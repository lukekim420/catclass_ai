{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 패키지 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from glob import glob\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout, Conv2D, MaxPool2D, Flatten, Dense\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctft_to_peaks(carr : np.ndarray, threshold = 1, max_peak_num = 10):\n",
    "    rising = np.zeros(shape=(max_peak_num, carr.shape[1]))\n",
    "    falling = np.zeros(shape=(max_peak_num , carr.shape[1]))\n",
    "    diff=np.diff(np.sign(carr.T-threshold), axis = 1)\n",
    "\n",
    "    for arr, num in [(rising, 2), (falling, -2)]:\n",
    "        a,b = np.where(diff==num)\n",
    "        for i in range(diff.shape[0]):\n",
    "            temp=b[a==i]\n",
    "            minlen = min(max_peak_num, len(temp))\n",
    "            arr[:minlen,i]=temp[:minlen]\n",
    "\n",
    "    return (rising, falling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram_db(file_path, sr=None, n_fft=2048, hop_length=160, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
    "  wav,sr = librosa.load(file_path,sr=sr)\n",
    "  if wav.shape[0]<int(1.3*sr):\n",
    "    wav=np.pad(wav,int(np.ceil((1.3*sr-wav.shape[0])/2)),mode='reflect')\n",
    "  else:\n",
    "    wav=wav[:int(1.3*sr)]\n",
    "  spec=librosa.feature.melspectrogram(y=wav, sr=sr, n_fft=n_fft,\n",
    "              hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
    "  spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
    "  return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_to_image(spec, eps=1e-6):\n",
    "  mean = spec.mean()\n",
    "  std = spec.std()\n",
    "  spec_norm = (spec - mean) / (std + eps)\n",
    "  spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "  spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "  spec_scaled = spec_scaled.astype(np.uint8)\n",
    "  return spec_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iscaterwaul(filedir):\n",
    "    print(\"Loading File\")\n",
    "    y, sr = librosa.load(filedir)\n",
    "    spec = np.abs(librosa.stft(y, hop_length=512))\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "    print(\"Filtering Noise\")\n",
    "    S_full, phase = librosa.magphase(librosa.stft(y)) #speech processing에 n_fft=512 권장된다고는함\n",
    "    S_filter = librosa.decompose.nn_filter(S_full,\n",
    "                                        aggregate=np.median,\n",
    "                                        metric='cosine',\n",
    "                                        width=int(librosa.time_to_frames(2, sr=sr)))\n",
    "    S_filter = np.minimum(S_full, S_filter)\n",
    "    margin_i, margin_v = 2, 10\n",
    "    power = 2\n",
    "    mask_i = librosa.util.softmask(S_filter,\n",
    "                                margin_i * (S_full - S_filter),\n",
    "                                power=power)\n",
    "    mask_v = librosa.util.softmask(S_full - S_filter,\n",
    "                                margin_v * S_filter,\n",
    "                                power=power)\n",
    "    S_foreground = mask_v * S_full\n",
    "    S_background = mask_i * S_full\n",
    "    rising, falling = ctft_to_peaks(S_foreground, threshold=0.1, max_peak_num=5)\n",
    "    #의미있는 부분만 잘라내기\n",
    "    cnt_mat = (rising > 1e-5).sum(axis=0)\n",
    "    thres = 5 - 0.5\n",
    "    cutpoint_rising = np.where(np.diff(np.sign(cnt_mat-thres))==2)[0]\n",
    "    cutpoint_falling = np.where(np.diff(np.sign(cnt_mat-thres))==-2)[0]+1\n",
    "    if(cnt_mat[0] > thres):\n",
    "        cutpoint_rising = np.insert(cutpoint_rising,0,0)\n",
    "    if len(cutpoint_rising)!=len(cutpoint_falling):\n",
    "            cutpoint_rising = cutpoint_rising[:-1]\n",
    "    print(\"Making Dir\")\n",
    "    os.mkdir(\"/catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0])\n",
    "    os.mkdir(\"/catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0]+'/wav')\n",
    "    os.mkdir(\"/catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0]+'/img')\n",
    "    print(\"Cutting File\")\n",
    "    for i in range(len(cutpoint_rising)):\n",
    "        if 1.3>=(librosa.frames_to_time(cutpoint_falling[i],sr=sr)-librosa.frames_to_time(cutpoint_rising[i],sr=sr))>=0.3:\n",
    "            os.system((\"ffmpeg -y -ss \" + str(librosa.frames_to_time(cutpoint_rising[i],sr=sr)) + \" -t \" + str(librosa.frames_to_time(cutpoint_falling[i],sr=sr)-librosa.frames_to_time(cutpoint_rising[i],sr=sr)) + \" -i \" +str(filedir)+\" /catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0]+\"/wav/\"+str(filedir.split('/')[-1].split(\".\")[0])+'_'+str(i)+\".wav -loglevel quiet\"))\n",
    "    base_dir = \"/catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0]+\"/wav\"\n",
    "    train_folder = glob(base_dir)\n",
    "    train_path = []\n",
    "    for folder in train_folder:\n",
    "        tmp = glob(folder + '/*')\n",
    "        train_path += tmp\n",
    "\n",
    "    print(\"Converting to img\")\n",
    "    for i in range(len(train_path)):\n",
    "        im = Image.fromarray(spec_to_image(get_melspectrogram_db(str(train_path[i]))))\n",
    "        im.save(\"/catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0]+\"/img/\"+str(train_path[i]).split(\"/\")[-1].split(\".\")[0]+'.jpeg')\n",
    "    \n",
    "    model = tf.keras.models.load_model('/catclass_ai/model_fuck.h5')\n",
    "\n",
    "    base_dir = \"/catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0]+\"/img\"\n",
    "    train_folder = glob(base_dir)\n",
    "    train_path = []\n",
    "    for folder in train_folder:\n",
    "        tmp = glob(folder + '/*')\n",
    "        train_path += tmp\n",
    "    print(\"Predicting\")\n",
    "    d=[[0,0]]\n",
    "    for i in range(len(train_path)):\n",
    "        img1 = load_img(train_path[i],target_size=(128,131))\n",
    "        imarr = img_to_array(img1)\n",
    "        X = np.expand_dims(imarr,axis=0)\n",
    "        val = model.predict(X,verbose=0)\n",
    "        d+=val\n",
    "    shutil.rmtree(\"/catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0], ignore_errors=True)\n",
    "    if d[0][0]>0:\n",
    "        return \"caterwaul\"\n",
    "    else:\n",
    "        return \"meow\"\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading File\n",
      "Filtering Noise\n",
      "Making Dir\n",
      "Cutting File\n",
      "Converting to img\n",
      "Predicting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'caterwaul'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iscaterwaul(\"/catclass_ai/test7.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir(\"/catclass_ai/temp/asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = '/catclass_ai/asdf.wav'\n",
    "os.mkdir(\"/catclass_ai/temp/\"+filedir.split(\"/\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
